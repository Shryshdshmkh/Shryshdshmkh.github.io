<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Spatial Neural Networks | Theory & Python Implementation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        neural: {
                            100: '#e6f7ff',
                            500: '#007bff',
                            900: '#003366',
                        },
                        gradient1: '#4facfe',
                        gradient2: '#00f2fe',
                    }
                }
            }
        }
    </script>
    <style>
        .code-block {
            font-family: 'Courier New', Courier, monospace;
            background-color: #2d3748;
            color: #f7fafc;
            border-radius: 0.375rem;
            overflow-x: auto;
        }
        
        .gradient-bg {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }
        
        .neuron {
            width: 30px;
            height: 30px;
            border-radius: 50%;
            background: linear-gradient(145deg, #4facfe, #00f2fe);
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        .pulse {
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(79, 172, 254, 0.7);
            }
            70% {
                transform: scale(1);
                box-shadow: 0 0 0 10px rgba(79, 172, 254, 0);
            }
            100% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(79, 172, 254, 0);
            }
        }
        
        .scroll-indicator {
            animation: bounce 2s infinite;
        }
        
        @keyframes bounce {
            0%, 20%, 50%, 80%, 100% {
                transform: translateY(0);
            }
            40% {
                transform: translateY(-20px);
            }
            60% {
                transform: translateY(-10px);
            }
        }
        
        .accordion-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
        }
    </style>
</head>
<body class="bg-gray-50">
    <!-- Header -->
    <header class="gradient-bg text-white shadow-xl">
        <div class="container mx-auto px-6 py-12">
            <div class="flex flex-col md:flex-row justify-between items-center">
                <div>
                    <h1 class="text-3xl md:text-5xl font-bold mb-4">Spatial Neural Networks</h1>
                    <p class="text-xl md:text-2xl opacity-90">Theory & Python Implementation</p>
                </div>
                <div class="mt-6 md:mt-0">
                    <div class="flex space-x-4">
                        <a href="#theory" class="px-6 py-2 bg-white text-blue-600 font-semibold rounded-full hover:bg-gray-100 transition">Theory</a>
                        <a href="#implement" class="px-6 py-2 bg-black bg-opacity-20 text-white font-semibold rounded-full hover:bg-opacity-30 transition">Implementation</a>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Scroll Indicator -->
    <div class="flex justify-center mt-2 scroll-indicator">
        <i class="fas fa-chevron-down text-gray-400 text-xl"></i>
    </div>

    <!-- Introduction -->
    <section id="intro" class="container mx-auto px-6 py-12 md:py-16">
        <div class="bg-white rounded-xl shadow-lg p-8 md:p-10">
            <h2 class="text-3xl md:text-4xl font-bold text-gray-800 mb-6">Introduction to Spatial Neural Networks</h2>
            <p class="text-lg text-gray-700 mb-6">
                Spatial Neural Networks are a specialized class of neural networks that explicitly consider spatial relationships and structure in the input data. 
                Unlike traditional networks that treat input features as independent, spatial networks preserve and leverage the geometric relationships between data points.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mt-8">
                <div class="bg-blue-50 p-6 rounded-lg border border-blue-100">
                    <div class="flex items-center mb-4">
                        <div class="neuron mr-3"></div>
                        <h3 class="text-xl font-bold text-blue-800">Spatial Awareness</h3>
                    </div>
                    <p class="text-gray-700">Built to handle spatially structured data like images, graphs, or geographical information</p>
                </div>
                <div class="bg-purple-50 p-6 rounded-lg border border-purple-100">
                    <div class="flex items-center mb-4">
                        <div class="neuron pulse mr-3"></div>
                        <h3 class="text-xl font-bold text-purple-800">Local Connectivity</h3>
                    </div>
                    <p class="text-gray-700">Neurons connect only to nearby units in the input space, mimicking biological vision systems</p>
                </div>
                <div class="bg-teal-50 p-6 rounded-lg border border-teal-100">
                    <div class="flex items-center mb-4">
                        <div class="neuron mr-3"></div>
                        <h3 class="text-xl font-bold text-teal-800">Parameter Sharing</h3>
                    </div>
                    <p class="text-gray-700">Reduces parameters by sharing weights across spatial locations</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Theory Section -->
    <section id="theory" class="bg-gray-50 py-12 md:py-16">
        <div class="container mx-auto px-6">
            <div class="bg-white rounded-xl shadow-lg overflow-hidden">
                <div class="gradient-bg text-white p-8">
                    <h2 class="text-3xl md:text-4xl font-bold">Theoretical Foundations</h2>
                    <p class="opacity-90 mt-2">Understanding the mathematical principles behind spatial neural networks</p>
                </div>
                
                <div class="p-8">
                    <!-- Architecture -->
                    <div class="mb-10">
                        <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                            <i class="fas fa-project-diagram text-blue-500 mr-3"></i>
                            1. Network Architecture
                        </h3>
                        <p class="text-gray-700 mb-4">
                            Spatial neural networks typically consist of layers designed to preserve spatial relationships:
                        </p>
                        <ul class="list-disc pl-6 space-y-2 text-gray-700 mb-6">
                            <li><span class="font-semibold">Input Layer</span>: Maintains spatial arrangement (e.g., 2D for images, 3D for videos)</li>
                            <li><span class="font-semibold">Hidden Layers</span>: Convolutional layers apply spatial filters to detect local patterns</li>
                            <li><span class="font-semibold">Pooling Layers</span>: Reduce spatial dimensions while preserving important features</li>
                            <li><span class="font-semibold">Output Layer</span>: May maintain spatial structure or flatten for classification</li>
                        </ul>
                        <div class="bg-gray-100 p-4 rounded-lg">
                            <img src="https://miro.medium.com/v2/resize:fit:1400/1*ZCjPUFrB6eHPRi4eyP6qaA.png" alt="Spatial Neural Network Architecture" class="rounded-lg mx-auto">
                            <p class="text-center text-sm text-gray-500 mt-2">Spatial Neural Network Architecture</p>
                        </div>
                    </div>
                    
                    <!-- Key Concepts -->
                    <div class="mb-10">
                        <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                            <i class="fas fa-lightbulb text-yellow-500 mr-3"></i>
                            2. Key Concepts
                        </h3>
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                            <div class="bg-blue-50 p-6 rounded-lg border-l-4 border-blue-500">
                                <h4 class="font-bold text-lg text-blue-800 mb-3">Local Receptive Fields</h4>
                                <p class="text-gray-700">
                                    Instead of connecting to all input neurons, each neuron connects only to a small region (receptive field) of the input space.
                                    This creates translation invariance - the network recognizes patterns regardless of their position.
                                </p>
                            </div>
                            <div class="bg-purple-50 p-6 rounded-lg border-l-4 border-purple-500">
                                <h4 class="font-bold text-lg text-purple-800 mb-3">Spatial Transformation</h4>
                                <p class="text-gray-700">
                                    Networks can learn spatial transformations like rotation, scaling, and warping through specialized layers.
                                    Spatial Transformer Networks explicitly model these transformations.
                                </p>
                            </div>
                            <div class="bg-green-50 p-6 rounded-lg border-l-4 border-green-500">
                                <h4 class="font-bold text-lg text-green-800 mb-3">Parameter Sharing</h4>
                                <p class="text-gray-700">
                                    The same weights are used across different spatial locations, dramatically reducing the number of parameters.
                                    This assumes that local features useful in one region are also useful elsewhere.
                                </p>
                            </div>
                            <div class="bg-teal-50 p-6 rounded-lg border-l-4 border-teal-500">
                                <h4 class="font-bold text-lg text-teal-800 mb-3">Multi-Scale Processing</h4>
                                <p class="text-gray-700">
                                    Networks process information at multiple spatial scales simultaneously,
                                    combining fine details with broader contextual information.
                                </p>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Mathematical Formulation -->
                    <div>
                        <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                            <i class="fas fa-square-root-alt text-red-500 mr-3"></i>
                            3. Mathematical Formulation
                        </h3>
                        <p class="text-gray-700 mb-4">
                            The fundamental operation in spatial neural networks is the <span class="font-semibold">convolution operation</span>.
                            For a 2D input <span class="italic">X</span> and kernel <span class="italic">K</span>, the output <span class="italic">Y</span> at position (i,j) is:
                        </p>
                        <div class="code-block p-4 mb-6">
                            Y[i,j] = ∑<sub>a</sub>∑<sub>b</sub> X[i+a, j+b] · K[a,b]
                        </div>
                        <p class="text-gray-700 mb-4">
                            Pooling operations reduce spatial dimensions while preserving important features:
                        </p>
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                            <div class="code-block p-4">
                                <p class="text-green-400 mb-2"># Max Pooling</p>
                                <p>Y[i,j] = max(X[i*s:(i+1)*s, j*s:(j+1)*s])</p>
                                <p class="text-green-400 mt-3 mb-2"># Average Pooling</p>
                                <p>Y[i,j] = mean(X[i*s:(i+1)*s, j*s:(j+1)*s])</p>
                            </div>
                            <div class="bg-gray-100 p-4 rounded-lg">
                                <p class="text-gray-700">
                                    Where <span class="font-semibold">s</span> is the stride/size of the pooling region.
                                    These operations make the representation invariant to small translations.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Implementation Section -->
    <section id="implement" class="container mx-auto px-6 py-12 md:py-16">
        <div class="bg-white rounded-xl shadow-lg overflow-hidden">
            <div class="gradient-bg text-white p-8">
                <h2 class="text-3xl md:text-4xl font-bold">Python Implementation</h2>
                <p class="opacity-90 mt-2">Practical implementation of spatial neural networks using PyTorch</p>
            </div>
            
            <div class="p-8">
                <!-- Setup -->
                <div class="mb-10">
                    <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                        <i class="fas fa-tools text-blue-500 mr-3"></i>
                        1. Environment Setup
                    </h3>
                    <p class="text-gray-700 mb-4">
                        We'll use PyTorch with its built-in convolutional neural network modules. Let's first install the required packages:
                    </p>
                    <div class="code-block p-4 mb-6">
                        <p class="text-green-400"># Install PyTorch with pip</p>
                        <p>pip install torch torchvision torchaudio</p>
                        <p class="mt-3 text-green-400"># For additional visualization</p>
                        <p>pip install matplotlib numpy</p>
                    </div>
                </div>
                
                <!-- Basic CNN -->
                <div class="mb-10">
                    <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                        <i class="fas fa-network-wired text-purple-500 mr-3"></i>
                        2. Implementing a Basic Spatial CNN
                    </h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                        <div class="code-block p-4 overflow-auto">
                            <p class="text-green-400"># Import necessary libraries</p>
                            <p>import torch</p>
                            <p>import torch.nn as nn</p>
                            <p>import torch.nn.functional as F</p>
                            <p class="mt-3 text-green-400"># Define a simple CNN</p>
                            <p>class SpatialCNN(nn.Module):</p>
                            <p class="pl-8">def __init__(self):</p>
                            <p class="pl-16">super(SpatialCNN, self).__init__()</p>
                            <p class="pl-16 text-green-400"># Convolutional layers</p>
                            <p class="pl-16">self.conv1 = nn.Conv2d(1, 32, 3)</p>
                            <p class="pl-16">self.conv2 = nn.Conv2d(32, 64, 3)</p>
                            <p class="pl-16 text-green-400"># Fully connected layers</p>
                            <p class="pl-16">self.fc1 = nn.Linear(64*12*12, 128)</p>
                            <p class="pl-16">self.fc2 = nn.Linear(128, 10)</p>
                            <p class="pl-8 mt-3">def forward(self, x):</p>
                            <p class="pl-16 text-green-400"># Apply spatial operations</p>
                            <p class="pl-16">x = F.relu(self.conv1(x))</p>
                            <p class="pl-16">x = F.max_pool2d(x, 2)</p>
                            <p class="pl-16">x = F.relu(self.conv2(x))</p>
                            <p class="pl-16">x = F.max_pool2d(x, 2)</p>
                            <p class="pl-16 text-green-400"># Flatten spatial features</p>
                            <p class="pl-16">x = x.view(x.size(0), -1)</p>
                            <p class="pl-16">x = F.relu(self.fc1(x))</p>
                            <p class="pl-16">x = self.fc2(x)</p>
                            <p class="pl-16">return F.log_softmax(x, dim=1)</p>
                        </div>
                        <div class="bg-gray-50 p-6 rounded-lg">
                            <h4 class="font-bold text-lg text-gray-800 mb-3">Key Components Explained</h4>
                            <ul class="space-y-3">
                                <li class="flex items-start">
                                    <span class="bg-blue-100 text-blue-800 rounded-full p-1 mr-2">
                                        <i class="fas fa-layer-group text-xs"></i>
                                    </span>
                                    <span><span class="font-semibold">Conv2d</span>: Performs 2D convolution with learnable filters</span>
                                </li>
                                <li class="flex items-start">
                                    <span class="bg-purple-100 text-purple-800 rounded-full p-1 mr-2">
                                        <i class="fas fa-filter text-xs"></i>
                                    </span>
                                    <span><span class="font-semibold">Max Pooling</span>: Reduces spatial dimensions by taking maximum values</span>
                                </li>
                                <li class="flex items-start">
                                    <span class="bg-green-100 text-green-800 rounded-full p-1 mr-2">
                                        <i class="fas fa-expand text-xs"></i>
                                    </span>
                                    <span><span class="font-semibold">Flattening</span>: Converts spatial features into vector for classification</span>
                                </li>
                                <li class="flex items-start">
                                    <span class="bg-yellow-100 text-yellow-800 rounded-full p-1 mr-2">
                                        <i class="fas fa-project-diagram text-xs"></i>
                                    </span>
                                    <span><span class="font-semibold">Forward Pass</span>: Defines how input flows through the spatial layers</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <!-- Training Example -->
                <div class="mb-10">
                    <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                        <i class="fas fa-brain text-teal-500 mr-3"></i>
                        3. Training the Spatial Network
                    </h3>
                    <div class="code-block p-4 mb-4 overflow-auto">
                        <p class="text-green-400"># Training loop example</p>
                        <p>model = SpatialCNN()</p>
                        <p>optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</p>
                        <p>criterion = nn.CrossEntropyLoss()</p>
                        <p class="mt-3">for epoch in range(10):</p>
                        <p class="pl-8">for images, labels in train_loader:</p>
                        <p class="pl-16">optimizer.zero_grad()</p>
                        <p class="pl-16">outputs = model(images)</p>
                        <p class="pl-16">loss = criterion(outputs, labels)</p>
                        <p class="pl-16">loss.backward()</p>
                        <p class="pl-16">optimizer.step()</p>
                    </div>
                    <div class="bg-yellow-50 border-l-4 border-yellow-400 p-4 rounded-lg">
                        <div class="flex">
                            <div class="flex-shrink-0">
                                <i class="fas fa-lightbulb text-yellow-500 text-xl"></i>
                            </div>
                            <div class="ml-3">
                                <h4 class="font-bold text-yellow-800">Training Tips</h4>
                                <p class="text-yellow-700">
                                    Use data augmentation to improve spatial generalization (random rotations, translations, flips).
                                    Learning rate scheduling helps fine-tune spatial features.
                                    Batch normalization between convolutional layers often improves convergence.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Advanced Techniques -->
                <div>
                    <h3 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                        <i class="fas fa-rocket text-red-500 mr-3"></i>
                        4. Advanced Spatial Architectures
                    </h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                        <!-- Accordion 1 -->
                        <div class="border rounded-lg overflow-hidden">
                            <button class="accordion-btn w-full px-6 py-4 text-left bg-gray-100 hover:bg-gray-200 font-bold flex justify-between items-center">
                                <span>U-Net Architecture</span>
                                <i class="fas fa-chevron-down transform transition-transform"></i>
                            </button>
                            <div class="accordion-content px-6">
                                <div class="pb-4">
                                    <p class="text-gray-700 mb-3">
                                        U-Net combines contracting (encoder) and expanding (decoder) paths with skip connections that preserve spatial information.
                                    </p>
                                    <div class="code-block p-3 text-sm">
                                        <p class="text-green-400"># Simplified U-Net block</p>
                                        <p>class UNetBlock(nn.Module):</p>
                                        <p class="pl-8">def __init__(self, in_ch, out_ch):</p>
                                        <p class="pl-16">super().__init__()</p>
                                        <p class="pl-16">self.conv = nn.Sequential(</p>
                                        <p class="pl-20">nn.Conv2d(in_ch, out_ch, 3, padding=1),</p>
                                        <p class="pl-20">nn.BatchNorm2d(out_ch),</p>
                                        <p class="pl-20">nn.ReLU(),</p>
                                        <p class="pl-20">nn.Conv2d(out_ch, out_ch, 3, padding=1),</p>
                                        <p class="pl-20">nn.BatchNorm2d(out_ch),</p>
                                        <p class="pl-20">nn.ReLU()</p>
                                        <p class="pl-16">)</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Accordion 2 -->
                        <div class="border rounded-lg overflow-hidden">
                            <button class="accordion-btn w-full px-6 py-4 text-left bg-gray-100 hover:bg-gray-200 font-bold flex justify-between items-center">
                                <span>Graph Convolutional Networks</span>
                                <i class="fas fa-chevron-down transform transition-transform"></i>
                            </button>
                            <div class="accordion-content px-6">
                                <div class="pb-4">
                                    <p class="text-gray-700 mb-3">
                                        GCNs extend spatial processing to irregular graphs using adjacency matrices and neighborhood aggregation.
                                    </p>
                                    <div class="code-block p-3 text-sm">
                                        <p class="text-green-400"># Basic GCN Layer</p>
                                        <p>class GCNLayer(nn.Module):</p>
                                        <p class="pl-8">def __init__(self, in_dim, out_dim):</p>
                                        <p class="pl-16">super().__init__()</p>
                                        <p class="pl-16">self.linear = nn.Linear(in_dim, out_dim)</p>
                                        <p class="pl-8">def forward(self, x, adj):</p>
                                        <p class="pl-16">x = torch.matmul(adj, x)</p>
                                        <p class="pl-16">x = self.linear(x)</p>
                                        <p class="pl-16">return F.relu(x)</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Accordion 3 -->
                        <div class="border rounded-lg overflow-hidden">
                            <button class="accordion-btn w-full px-6 py-4 text-left bg-gray-100 hover:bg-gray-200 font-bold flex justify-between items-center">
                                <span>Spatial Transformer Networks</span>
                                <i class="fas fa-chevron-down transform transition-transform"></i>
                            </button>
                            <div class="accordion-content px-6">
                                <div class="pb-4">
                                    <p class="text-gray-700 mb-3">
                                        STNs learn to apply spatial transformations to input data to improve invariance.
                                    </p>
                                    <div class="code-block p-3 text-sm">
                                        <p class="text-green-400"># STN Localization Network</p>
                                        <p>class STN(nn.Module):</p>
                                        <p class="pl-8">def __init__(self):</p>
                                        <p class="pl-16">super().__init__()</p>
                                        <p class="pl-16">self.localization = nn.Sequential(</p>
                                        <p class="pl-20">nn.Conv2d(1, 8, 5), nn.MaxPool2d(2),</p>
                                        <p class="pl-20">nn.Conv2d(8, 10, 5), nn.MaxPool2d(2)</p>
                                        <p class="pl-16">)</p>
                                        <p class="pl-16">self.fc_loc = nn.Sequential(</p>
                                        <p class="pl-20">nn.Linear(10*3*3, 32),</p>
                                        <p class="pl-20">nn.Linear(32, 3*2) # Affine transform</p>
                                        <p class="pl-16">)</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <!-- Accordion 4 -->
                        <div class="border rounded-lg overflow-hidden">
                            <button class="accordion-btn w-full px-6 py-4 text-left bg-gray-100 hover:bg-gray-200 font-bold flex justify-between items-center">
                                <span>3D Convolutions</span>
                                <i class="fas fa-chevron-down transform transition-transform"></i>
                            </button>
                            <div class="accordion-content px-6">
                                <div class="pb-4">
                                    <p class="text-gray-700 mb-3">
                                        Extend spatial processing to volumetric data like medical scans or video sequences.
                                    </p>
                                    <div class="code-block p-3 text-sm">
                                        <p class="text-green-400"># 3D CNN Layer</p>
                                        <p>class Conv3DLayer(nn.Module):</p>
                                        <p class="pl-8">def __init__(self, in_ch, out_ch):</p>
                                        <p class="pl-16">super().__init__()</p>
                                        <p class="pl-16">self.conv = nn.Conv3d(in_ch, out_ch, 3, padding=1)</p>
                                        <p class="pl-8">def forward(self, x):</p>
                                        <p class="pl-16">return F.relu(self.conv(x))</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Applications Section -->
    <section class="container mx-auto px-6 py-12 md:py-16">
        <div class="bg-white rounded-xl shadow-lg overflow-hidden">
            <div class="gradient-bg text-white p-8">
                <h2 class="text-3xl md:text-4xl font-bold">Real-World Applications</h2>
                <p class="opacity-90 mt-2">Where spatial neural networks shine</p>
            </div>
            
            <div class="p-8">
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
                    <!-- App 1 -->
                    <div class="border rounded-lg overflow-hidden hover:shadow-md transition">
                        <div class="h-48 bg-blue-100 flex items-center justify-center">
                            <i class="fas fa-eye text-6xl text-blue-500"></i>
                        </div>
                        <div class="p-6">
                            <h3 class="text-xl font-bold text-gray-800 mb-2">Medical Image Analysis</h3>
                            <p class="text-gray-700">
                                Segmentation of tumors in MRI scans, detection of anomalies in X-rays, and 3D reconstruction of organs.
                            </p>
                        </div>
                    </div>
                    
                    <!-- App 2 -->
                    <div class="border rounded-lg overflow-hidden hover:shadow-md transition">
                        <div class="h-48 bg-green-100 flex items-center justify-center">
                            <i class="fas fa-satellite-dish text-6xl text-green-500"></i>
                        </div>
                        <div class="p-6">
                            <h3 class="text-xl font-bold text-gray-800 mb-2">Satellite Imagery</h3>
                            <p class="text-gray-700">
                                Land classification, deforestation monitoring, and urban planning using spatial-temporal analysis.
                            </p>
                        </div>
                    </div>
                    
                    <!-- App 3 -->
                    <div class="border rounded-lg overflow-hidden hover:shadow-md transition">
                        <div class="h-48 bg-purple-100 flex items-center justify-center">
                            <i class="fas fa-robot text-6xl text-purple-500"></i>
                        </div>
                        <div class="p-6">
                            <h3 class="text-xl font-bold text-gray-800 mb-2">Autonomous Vehicles</h3>
                            <p class="text-gray-700">
                                Processing LiDAR and camera data for road scene understanding, object detection, and path planning.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-900 text-white py-12">
        <div class="container mx-auto px-6">
            <div class="flex flex-col md:flex-row justify-between">
                <div class="mb-8 md:mb-0">
                    <h3 class="text-xl font-bold mb-4">Spatial Neural Networks</h3>
                    <p class="text-gray-400 max-w-md">
                        Exploring the intersection of spatial reasoning and deep learning for structured data analysis.
                    </p>
                </div>
                <div class="grid grid-cols-2 md:grid-cols-3 gap-8">
                    <div>
                        <h4 class="font-bold mb-4">Resources</h4>
                        <ul class="space-y-2 text-gray-400">
                            <li><a href="#" class="hover:text-white">Papers</a></li>
                            <li><a href="#" class="hover:text-white">Datasets</a></li>
                            <li><a href="#" class="hover:text-white">Tutorials</a></li>
                        </ul>
                    </div>
                    <div>
                        <h4 class="font-bold mb-4">Frameworks</h4>
                        <ul class="space-y-2 text-gray-400">
                            <li><a href="#" class="hover:text-white">PyTorch</a></li>
                            <li><a href="#" class="hover:text-white">TensorFlow</a></li>
                            <li><a href="#" class="hover:text-white">PyTorch Geometric</a></li>
                        </ul>
                    </div>
                    <div>
                        <h4 class="font-bold mb-4">Connect</h4>
                        <div class="flex space-x-4">
                            <a href="#" class="text-gray-400 hover:text-white text-xl"><i class="fab fa-github"></i></a>
                            <a href="#" class="text-gray-400 hover:text-white text-xl"><i class="fab fa-twitter"></i></a>
                            <a href="#" class="text-gray-400 hover:text-white text-xl"><i class="fab fa-linkedin"></i></a>
                        </div>
                    </div>
                </div>
            </div>
            <div class="border-t border-gray-800 mt-12 pt-8 text-center text-gray-400">
                <p>© 2023 Spatial Neural Networks Guide. All rights reserved.</p>
            </div>
        </div>
    </footer>

    <script>
        // Accordion functionality
        document.querySelectorAll('.accordion-btn').forEach(button => {
            button.addEventListener('click', () => {
                const content = button.nextElementSibling;
                const icon = button.querySelector('i');
                
                if (content.style.maxHeight) {
                    content.style.maxHeight = null;
                    icon.classList.remove('rotate-180');
                } else {
                    content.style.maxHeight = content.scrollHeight + 'px';
                    icon.classList.add('rotate-180');
                }
            });
        });
        
        // Smooth scrolling for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>
</html>
